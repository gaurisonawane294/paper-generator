[
    {
        "id": 1,
        "timestamp": "2025-03-12 02:08:03",
        "questions": "Question Paper\n==================================================\n\nDATA STRUCTURES AND ALGORITHMS EXAMINATION\nTime: 3 Hours                                                  Maximum Marks: 96\n\nInstructions:\n1. All questions are compulsory\n2. Write answers clearly and neatly\n3. Start each section on a new page\n4. Numbers to the right indicate full marks\n\nSubject: Data Structures and Algorithms\nTopic: All topics covered\nSyllabus Coverage: All topics covered\nDifficulty Level: Hard\n\n\n**Section A: Multiple Choice Questions (10 \u00d7 1 = 10 marks)**\n\n1. Which of the following data structures uses a hashing function for efficient search and insertion?\n    (a) Linked List      (b) Hash Table      (c) Binary Tree      (d) Stack [1 Mark]\n\n2. What is the time complexity of searching for an element in a sorted array using binary search?\n    (a) O(n)            (b) O(log n)       (c) O(n log n)     (d) O(n^2) [1 Mark]\n\n3. Which sorting algorithm has the best average-case time complexity?\n    (a) Bubble Sort      (b) Merge Sort      (c) Insertion Sort   (d) Selection Sort [1 Mark]\n\n4. A graph with no cycles is called a:\n    (a) Complete Graph    (b) Connected Graph (c) Acyclic Graph   (d) Bipartite Graph [1 Mark]\n\n5. Which traversal technique visits the root node last?\n    (a) Preorder         (b) Inorder        (c) Postorder       (d) Level Order [1 Mark]\n\n6. The process of converting an infix expression to postfix notation requires the use of a:\n    (a) Queue          (b) Stack           (c) Linked List     (d) Tree [1 Mark]\n\n7. Which data structure is typically used to implement a priority queue?\n    (a) Array           (b) Heap            (c) Stack          (d) Linked List [1 Mark]\n\n8. Dijkstra's algorithm is used to find the:\n    (a) Shortest path in a graph   (b) Minimum spanning tree   (c) All pairs shortest paths   (d) Topological sort [1 Mark]\n\n9. The time complexity of inserting an element at the beginning of a singly linked list is:\n    (a) O(n)            (b) O(log n)       (c) O(1)           (d) O(n^2) [1 Mark]\n\n10. Which of the following is NOT a dynamic programming algorithm?\n    (a) Floyd-Warshall  (b) Knapsack        (c) QuickSort        (d) Bellman-Ford [1 Mark]\n\n\n**Section B: Short Answer Questions (12 \u00d7 3 = 36 marks)**\n\n1. Explain the difference between a stack and a queue. Give real-world examples of their applications. [3 Marks]\n2. Briefly describe three different collision resolution techniques used in hash tables. [3 Marks]\n3. Write pseudocode for a recursive function to calculate the factorial of a given number. [3 Marks]\n4. Explain the concept of dynamic programming and provide an example. [3 Marks]\n5. What is the advantage of using adjacency lists over adjacency matrices for representing graphs? [3 Marks]\n6. Describe the steps involved in inserting a node into a binary search tree. [3 Marks]\n7. Explain the difference between depth-first search (DFS) and breadth-first search (BFS). [3 Marks]\n8. Analyze the time complexity of the merge sort algorithm. [3 Marks]\n9. Briefly explain the concept of recursion and provide an example of a recursive function. [3 Marks]\n10. What are the advantages and disadvantages of using a linked list over an array? [3 Marks]\n11. Explain the working principle of the heap sort algorithm. [3 Marks]\n12.  Describe the concept of a balanced search tree and give two examples of balanced tree structures. [3 Marks]\n\n\n**Section C: Long Answer Questions (10 \u00d7 5 = 50 marks)**\n\n1. Implement a stack using a linked list in C++ or Java. Include functions for push, pop, and peek operations. [5 Marks]\n2.  Design an algorithm to find the strongly connected components in a directed graph. Explain its time complexity. [5 Marks]\n3. You are given a large dataset of unsorted integers. Discuss the most appropriate sorting algorithm to use, justifying your choice based on time complexity and memory usage.  [5 Marks]\n4. Implement a function to check if a given binary tree is a binary search tree. [5 Marks]\n5. Design an algorithm to find the shortest path between two nodes in a weighted graph using Dijkstra's algorithm.  [5 Marks]\n6.  Discuss the different ways to represent a graph.  Compare and contrast their advantages and disadvantages in terms of space and time complexity for various graph operations (e.g., adding an edge, checking for the existence of an edge). [5 Marks]\n7.  You are designing a system to store and retrieve large amounts of data.  Discuss the trade-offs between using a B-tree and a hash table as the underlying data structure.  Consider factors such as search performance, insertion/deletion performance, and space utilization. [5 Marks]\n8.  Given a set of tasks with deadlines and profits, design a dynamic programming algorithm to schedule the tasks in a way that maximizes the total profit.  Assume that each task takes one unit of time. [5 Marks]\n9.  Implement a queue using two stacks.  Include functions for enqueue and dequeue operations. Analyze the time complexity of your implementation. [5 Marks]\n10. Explain the concept of amortized analysis.  Demonstrate how amortized analysis can be used to determine the time complexity of a sequence of operations on a dynamic array. [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\n**Section A: Multiple Choice Questions**\n\n1. **(b) Hash Table**  Hash tables use a hash function to map keys to indices in an array, allowing for efficient search and insertion (average-case O(1)). *Key Concept: Hashing*\n2. **(b) O(log n)** Binary search repeatedly divides the search interval in half. *Key Concept: Divide and Conquer*\n3. **(b) Merge Sort** Merge sort has a consistent O(n log n) time complexity in all cases (best, average, worst). *Key Concept: Sorting Algorithms*\n4. **(c) Acyclic Graph**  An acyclic graph is a graph without cycles. *Key Concept: Graph Theory*\n5. **(c) Postorder**  Postorder traversal visits the left subtree, then the right subtree, and finally the root. *Key Concept: Tree Traversal*\n6. **(b) Stack**  A stack is used to store operators during infix to postfix conversion. *Key Concept: Expression Evaluation*\n7. **(b) Heap**  Heaps are commonly used to implement priority queues because they efficiently maintain the highest (or lowest) priority element. *Key Concept: Priority Queue*\n8. **(a) Shortest path in a graph** Dijkstra's algorithm finds the shortest paths from a source node to all other nodes in a weighted graph. *Key Concept: Shortest Path Algorithms*\n9. **(c) O(1)** Inserting at the beginning just requires updating the head pointer. *Key Concept: Linked List Operations*\n10. **(c) QuickSort** QuickSort is a divide-and-conquer sorting algorithm, not a dynamic programming algorithm.  *Key Concept: Algorithm Categories*\n\n\n**Section B: Short Answer Questions**\n\n1. **Stack vs. Queue:**\n    * **Stack:** LIFO (Last-In, First-Out).  Example: Function call stack.\n    * **Queue:** FIFO (First-In, First-Out). Example: Print queue.\n\n2. **Hash Table Collision Resolution:**\n    * **Separate Chaining:** Store colliding elements in a linked list at the same index.\n    * **Open Addressing (Linear Probing):** If a collision occurs, probe the next available slot.\n    * **Quadratic Probing:** Probe at increasing intervals (1, 4, 9, etc.) to reduce clustering.\n\n3. **Recursive Factorial (Pseudocode):**\n    ```\n    function factorial(n):\n      if n == 0:\n        return 1\n      else:\n        return n * factorial(n-1)\n    ```\n\n4. **Dynamic Programming:**\n    * Breaking down a problem into smaller overlapping subproblems.\n    * Storing solutions to subproblems to avoid recomputation.  \n    * Example: Fibonacci sequence calculation.\n\n5. **Adjacency List vs. Adjacency Matrix:**\n    * Adjacency lists use less space for sparse graphs.  Edge lookups are O(degree(v)), where v is the vertex.\n    * Adjacency matrices use more space (O(V^2)) but provide constant-time edge lookups (O(1)).\n\n6. **BST Insertion:**\n    * Start at the root.\n    * Compare the new node's key with the current node's key.\n    * Go left if smaller, right if larger.\n    * Insert when you reach an empty spot (NULL).\n\n7. **DFS vs. BFS:**\n    * **DFS:** Explores a branch as deeply as possible before backtracking. Uses a stack or recursion.\n    * **BFS:** Explores level by level. Uses a queue.\n\n8. **Merge Sort Time Complexity:**\n    * Dividing: O(log n)\n    * Merging: O(n) at each level\n    * Overall: O(n log n)\n\n9. **Recursion:**\n    * A function calling itself directly or indirectly.\n    * Example: Factorial calculation (as shown above).\n    * Base case is essential to prevent infinite recursion.\n\n10. **Linked List vs. Array:**\n    * **Linked List:** Dynamic size, efficient insertion/deletion, but slower access (O(n)).\n    * **Array:** Fixed size, faster access (O(1)), but slower insertion/deletion (especially in the middle).\n\n11. **Heap Sort:**\n    * Build a max-heap from the input array.\n    * Repeatedly swap the root (maximum element) with the last element and heapify the reduced heap.\n\n12. **Balanced Search Tree:**\n    * A search tree where the height is kept relatively small (O(log n)). This ensures efficient search, insertion, and deletion operations.\n    * Examples: AVL tree, Red-Black tree.\n\n\n**Section C: Long Answer Questions**\n\n1. **Stack using Linked List (C++):**\n    ```cpp\n    #include <iostream>\n\n    struct Node {\n        int data;\n        Node* next;\n    };\n\n    class Stack {\n        Node* top;\n    public:\n        Stack() : top(nullptr) {}\n\n        void push(int val) {\n            Node* newNode = new Node{val, top};\n            top = newNode;\n        }\n\n        int pop() { // ... (implementation for pop and peek)\n        }\n\n        int peek() { // ...\n        }\n    };\n    ```\n    *(Include proper error handling for pop/peek on empty stack)*\n\n\n2. **Strongly Connected Components (Tarjan's Algorithm):**\n    * Use Depth-First Search (DFS).\n    * Maintain a stack of visited nodes.\n    * Use low-link values to track earliest reachable ancestor in the DFS tree.\n    * When a node's low-link value equals its discovery time, a strongly connected component is found.\n    * Time Complexity: O(V + E)\n\n3. **Sorting Large Dataset:**\n    * **Merge Sort or QuickSort:**  Merge sort is a good choice due to its guaranteed O(n log n) time complexity and stable sorting.  QuickSort can be faster on average but has a worst-case O(n^2) time complexity. External merge sort is highly suitable for extremely large datasets that don't fit in memory.\n    * **Avoid Bubble Sort, Insertion Sort, Selection Sort:** O(n^2) complexity.\n\n4. **Check if Binary Tree is BST (C++):**\n    ```cpp\n    bool isBST(Node* root, int minVal = INT_MIN, int maxVal = INT_MAX) {\n        if (!root) return true;\n        if (root->data <= minVal || root->data >= maxVal) return false;\n        return isBST(root->left, minVal, root->data) && isBST(root->right, root->data, maxVal);\n    }\n    ```\n\n5. **Dijkstra's Algorithm:**\n    * Initialize distances to infinity, source distance to 0.\n    * Use a priority queue to store nodes based on distance.\n    * Repeatedly extract the node with the smallest distance (u).\n    * Update distances of neighbors (v) if a shorter path is found: dist[v] = min(dist[v], dist[u] + weight(u, v)).\n\n6. **Graph Representations:**\n    * **Adjacency Matrix:**  O(1) edge lookup, O(V^2) space.\n    * **Adjacency List:**  O(degree(v)) edge lookup, O(V + E) space.  Better for sparse graphs.\n    * **Incidence Matrix:**  Represents relationships between vertices and edges.\n\n7. **B-tree vs. Hash Table:**\n    * **B-tree:** Better for range queries, ordered data, predictable performance. Disk-friendly.\n    * **Hash Table:** Faster average-case lookups (O(1)), but can degrade to O(n) in worst-case scenarios (many collisions). Not good for range queries.\n\n8. **Task Scheduling (Dynamic Programming):**\n    * Sort tasks by deadlines.\n    * Create a table `dp[i][j]` where `dp[i][j]` is the maximum profit achievable by completing `i` tasks within time `j`.\n    * `dp[i][j] = max(dp[i-1][j], profit[i] + dp[i-1][j-1])`  if `j >= deadline[i]`\n\n\n9. **Queue using Two Stacks:**\n    * **Enqueue:** Push onto stack1.\n    * **Dequeue:** If stack2 is empty, pop all elements from stack1 and push onto stack2.  Then pop from stack2.\n    * Amortized O(1) time complexity.\n\n10. **Amortized Analysis:**\n    * Analyzes the average cost of operations over a sequence of operations.\n    * **Dynamic Array:**  Doubling the array size when full.  Although resizing is O(n), the amortized cost of insertion is O(1).  Explain using the aggregate method or the accounting method.\n\n\nThis comprehensive answer key provides a detailed explanation for each question, covering key concepts, algorithms, and data structures.  It serves as a valuable resource for students to understand the solutions and improve their understanding of Data Structures and Algorithms. Remember to include specific code implementations where requested for Section C and adjust pseudocode syntax as needed.",
        "metadata": {
            "subject": "Data Structures and Algorithms",
            "topic": "",
            "difficulty": "Hard",
            "total_marks": 100,
            "num_mcq": 10,
            "num_3_marks": 12,
            "num_5_marks": 10
        }
    },
    {
        "id": 2,
        "timestamp": "2025-03-12 02:20:44",
        "questions": "Question Paper\n==================================================\n\n## CUSTOM EXAMINATION\n\n**Time:** 3 Hours                                                  **Maximum Marks:** 35\n\n**Instructions:**\n1. All questions are compulsory.\n2. Write answers clearly and neatly.\n3. Start each section on a new page.\n4. Numbers to the right indicate full marks.\n\n**Subject:** Computer Organization and Architecture\n**Topic:** Fundamentals of Computer Architecture and Organization\n**Syllabus Coverage:** Units I - VI (as specified in the prompt)\n**Difficulty Level:** Medium\n\n\n**Section A: Multiple Choice Questions (5 \u00d7 1 = 5 marks)**\n\n1.  Which of the following is NOT a basic data type in computers?\n    (a) Integer      (b) Floating-point      (c) Character      (d) Polynomial [1 Mark]\n\n2.  The register transfer language statement MAR \u2190 PC represents:\n    (a) Transferring the contents of PC to MAR.\n    (b) Transferring the contents of MAR to PC.\n    (c) Adding the contents of PC and MAR.\n    (d) Comparing the contents of PC and MAR. [1 Mark]\n\n3.  In a microprogrammed control unit, the control signals are generated by:\n    (a) The CPU.      (b) The control memory.      (c) The ALU.     (d) The main memory. [1 Mark]\n\n4.  Which addressing mode uses a register to store the memory address?\n    (a) Direct      (b) Indirect       (c) Register      (d) Immediate [1 Mark]\n\n5.  DMA stands for:\n    (a) Direct Memory Access    (b) Dynamic Memory Allocation    (c) Digital Memory Address   (d) Distributed Memory Architecture [1 Mark]\n\n\n**Section B: Short Answer Questions (5 \u00d7 3 = 15 marks)**\n\n1.  Explain the difference between fixed-point and floating-point representation of numbers. Give an example of each. [3 Marks]\n\n2.  Describe the function of three-state bus buffers in memory transfer operations. [3 Marks]\n\n3.  What is an instruction cycle? Briefly explain the fetch and execute phases of an instruction cycle. [3 Marks]\n\n4.  Explain the concept of pipelining and its advantages in improving CPU performance. [3 Marks]\n\n5.  Differentiate between synchronous and asynchronous data transfer in input/output operations. [3 Marks]\n\n\n\n**Section C: Long Answer Questions (3 \u00d7 5 = 15 marks)**\n\n1.  Design a 4-bit accumulator unit using logic gates and registers. Explain its working with the help of a diagram. [5 Marks]\n\n2.  A computer system uses a 2-level cache memory. The access times for the L1 cache, L2 cache, and main memory are 2 ns, 10 ns, and 100 ns, respectively. The hit ratios for L1 and L2 caches are 80% and 95%, respectively. Calculate the average memory access time. [5 Marks]\n\n3.  Consider a scenario where a program needs to calculate the sum of elements in a large array. Discuss how vector processing can be used to speed up this computation. Compare and contrast vector processing with traditional scalar processing in this context. [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\nSection A: Multiple Choice Questions\n\n1.  **(d) Polynomial**\n    * Polynomials are not a basic data type directly represented in hardware. Computers use integers, floating-point numbers, and characters as fundamental data types.\n    * Key concept tested: Basic data types in computer systems.\n\n2.  **(a) Transferring the contents of PC to MAR.**\n    *  MAR \u2190 PC means the contents of the Program Counter (PC) are copied into the Memory Address Register (MAR). This typically happens during the fetch phase of the instruction cycle.\n    * Key concept tested: Register Transfer Language and instruction fetch.\n\n3.  **(b) The control memory.**\n    * In a microprogrammed control unit, the control memory stores microinstructions, which define the control signals for each micro-operation.\n    * Key concept tested: Microprogrammed control unit organization.\n\n4.  **(b) Indirect**\n    * In indirect addressing, the register holds the memory address where the actual operand is stored.  \n    * Key concept tested: Addressing modes.\n\n5.  **(a) Direct Memory Access**\n    * DMA allows I/O devices to transfer data directly to/from main memory without involving the CPU.\n    * Key concept tested: I/O techniques and DMA.\n\n\nSection B: Short Answer Questions\n\n1. **Fixed-Point vs. Floating-Point Representation:**\n    * **Fixed-Point:**\n        * Represents numbers with a fixed decimal point.\n        * Simpler hardware implementation.\n        * Limited range and precision.\n        * Example: Representing 12.34 as 1234, assuming two decimal places.\n    * **Floating-Point:**\n        * Represents numbers in scientific notation (mantissa \u00d7 base<sup>exponent</sup>).\n        * Wider range and higher precision.\n        * More complex hardware.\n        * Example: Representing 12.34 as 1.234 \u00d7 10<sup>1</sup>.\n    * Key Concepts: Number representation, range, precision.\n\n2. **Function of Three-State Bus Buffers:**\n    * **Enable data transfer to the bus:** When enabled, a buffer allows data from a specific device to be placed onto the bus.\n    * **Isolate devices from the bus:** When disabled (high-impedance state), the buffer effectively disconnects the device from the bus, preventing interference with other devices.\n    * **Prevent data collisions:** Multiple devices can share the same bus, but only one buffer should be enabled at any given time to avoid conflicts.\n    * Key Concepts: Bus organization, data transfer, three-state logic.\n\n3. **Instruction Cycle:**\n    * The sequence of steps performed by the CPU to execute a single instruction.\n    * **Fetch Phase:**\n        * The instruction is retrieved from memory at the address specified by the PC and loaded into the Instruction Register (IR).\n        * PC is incremented to point to the next instruction.\n    * **Execute Phase:**\n        * The instruction in the IR is decoded.\n        * The required operands are fetched.\n        * The operation specified by the instruction is executed.\n        * The result is stored.\n    * Key Concepts: Instruction execution, fetch-execute cycle, CPU operation.\n\n4. **Pipelining:**\n    * Overlapping the execution of multiple instructions.\n    * Dividing the instruction execution process into stages.\n    * Each stage works on a different instruction concurrently.\n    * **Advantages:**\n        * Increased instruction throughput.\n        * Improved CPU performance (reduced overall execution time).\n    * Key Concepts: Pipelining, instruction throughput, performance enhancement.\n\n5. **Synchronous vs. Asynchronous Data Transfer:**\n    * **Synchronous:**\n        * Data transfer is controlled by a clock signal.\n        * Sender and receiver synchronize with the clock.\n        * Simpler to implement but less flexible.\n    * **Asynchronous:**\n        * Data transfer is controlled by handshaking signals (e.g., ready, acknowledge).\n        * More flexible for devices with different speeds.\n        * More complex control logic required.\n    * Key Concepts: I/O data transfer, synchronization, handshaking.\n\n\nSection C: Long Answer Questions\n\n1. **4-Bit Accumulator Design:**\n\n    * **Diagram:**  A diagram showing a 4-bit register, a 4-bit adder, and control logic. Inputs would include the 4-bit data input and a control signal (e.g., \"Add\"). The output would be the 4-bit sum stored in the register.\n    * **Working:** \n        1. The initial value of the accumulator is stored in the register.\n        2. New data is presented at the input.\n        3. When the \"Add\" signal is activated, the adder adds the input data to the current value in the register.\n        4. The sum is then stored back into the register, updating the accumulator value.\n    * **Components:** 4-bit full adder, 4 D-flip-flops (register), control logic.\n    * Key Concepts: Accumulator, adder, register, digital logic design.\n\n\n2. **Average Memory Access Time Calculation:**\n\n    * **Formula:** Average Access Time = H1 \u00d7 T1 + (1 - H1) \u00d7 (H2 \u00d7 T2 + (1 - H2) \u00d7 T3)\n        * H1: Hit ratio of L1 cache (0.80)\n        * T1: Access time of L1 cache (2 ns)\n        * H2: Hit ratio of L2 cache (0.95)\n        * T2: Access time of L2 cache (10 ns)\n        * T3: Access time of main memory (100 ns)\n    * **Calculation:**\n        Average Access Time = 0.80 \u00d7 2 + (1 - 0.80) \u00d7 (0.95 \u00d7 10 + (1 - 0.95) \u00d7 100)\n        = 1.6 + 0.2 \u00d7 (9.5 + 0.05 \u00d7 100)\n        = 1.6 + 0.2 \u00d7 (9.5 + 5)\n        = 1.6 + 0.2 \u00d7 14.5\n        = 1.6 + 2.9\n        = 4.5 ns\n    * Key Concepts: Cache memory, hit ratio, average access time.\n\n3. **Vector Processing for Array Summation:**\n\n    * **Vector Processing:** Processing multiple array elements simultaneously using vector instructions. A vector instruction operates on a vector (array) of data elements.\n    * **Scalar Processing:** Processing one array element at a time using scalar instructions. A loop is typically used to iterate through the array.\n    * **Example:** Consider a vector processor with a vector length of 4. To calculate the sum of an 8-element array, the vector processor can perform two vector additions:\n        1. Add elements 0-3 simultaneously.\n        2. Add elements 4-7 simultaneously.\n        3. Finally, add the two partial sums.\n    * **Comparison:**\n        * **Vector Processing:** Faster for large arrays due to parallel processing, requires specialized hardware (vector registers, vector instructions).\n        * **Scalar Processing:** Simpler hardware, slower for large arrays due to sequential processing.\n    * Key Concepts: Vector processing, scalar processing, SIMD (Single Instruction Multiple Data), performance comparison.",
        "metadata": {
            "subject": "Custom",
            "topic": "",
            "difficulty": "Medium",
            "total_marks": 35,
            "num_mcq": 5,
            "num_3_marks": 5,
            "num_5_marks": 3
        }
    },
    {
        "id": 3,
        "timestamp": "2025-03-12 02:25:13",
        "questions": "Question Paper\n==================================================\n\nDATA STRUCTURES AND ALGORITHMS EXAMINATION\nTime: 3 Hours                                                  Maximum Marks: 35\n\nInstructions:\n1. All questions are compulsory\n2. Write answers clearly and neatly\n3. Start each section on a new page\n4. Numbers to the right indicate full marks\n\nSubject: Data Structures and Algorithms\nTopic: All topics covered\nSyllabus Coverage: All topics covered\nDifficulty Level: Medium\n\n\n**Section A: Multiple Choice Questions (5 \u00d7 1 = 5 marks)**\n\n1. Which data structure follows the LIFO principle?\n    (a) Queue        (b) Stack        (c) Linked List        (d) Tree [1 Mark]\n\n2. Which of the following is NOT a searching algorithm?\n    (a) Linear Search     (b) Binary Search    (c) Bubble Sort    (d) Depth-First Search [1 Mark]\n\n3. What is the time complexity of inserting an element at the beginning of a singly linked list?\n    (a) O(n)        (b) O(1)        (c) O(log n)       (d) O(n log n) [1 Mark]\n\n4. A binary search tree is balanced if:\n    (a) It has the same number of nodes on the left and right subtrees.\n    (b) The height difference between the left and right subtrees is at most 1.\n    (c) All nodes have the same value.\n    (d) It is a complete binary tree. [1 Mark]\n\n5. Which sorting algorithm has an average-case time complexity of O(n log n) and is based on divide and conquer?\n    (a) Bubble Sort     (b) Insertion Sort    (c) Merge Sort     (d) Selection Sort [1 Mark]\n\n\n\n**Section B: Short Answer Questions (5 \u00d7 3 = 15 marks)**\n\n1. Explain the difference between a stack and a queue. Provide real-world examples of where each data structure is used. [3 Marks]\n\n2. Given a sorted array of integers, describe the steps involved in performing a binary search to find a specific element.  [3 Marks]\n\n3.  What is the advantage of using a circular linked list over a linear linked list?  Give a scenario where a circular linked list is more suitable. [3 Marks]\n\n4. Calculate the time complexity of the following code snippet:\n\n```java\nfor (int i = 0; i < n; i++) {\n    for (int j = i; j < n; j++) {\n        // Some constant time operation\n    }\n}\n```\n\n[3 Marks]\n\n\n5. Explain the concept of recursion.  Provide an example of a recursive function to calculate the factorial of a number. [3 Marks]\n\n\n**Section C: Long Answer Questions (3 \u00d7 5 = 15 marks)**\n\n1.  You are tasked with designing a system to manage patient records in a hospital.  Discuss the data structure(s) you would choose to store and retrieve patient information efficiently.  Justify your choices considering factors like search speed, insertion/deletion efficiency, and memory usage. [5 Marks]\n\n2.  Implement a function in pseudocode or a programming language of your choice to reverse a singly linked list iteratively.  Explain the logic and steps involved in your implementation.  [5 Marks]\n\n3.  Consider a scenario where you need to sort a large dataset of customer orders based on their order dates. Analyze the suitability of Merge Sort and Quick Sort algorithms for this task. Discuss their time complexities in best-case, average-case, and worst-case scenarios.  Which algorithm would you prefer and why? [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\n**Section A: Multiple Choice Questions**\n\n1.  **(b) Stack**\n    * Stacks operate on the Last-In, First-Out (LIFO) principle.  The last element added is the first one to be removed.\n    * Key Concept: Stack data structure.\n\n\n2.  **(c) Bubble Sort**\n    * Bubble Sort is a sorting algorithm, not a searching algorithm. Searching algorithms aim to find a specific element within a data structure.\n    * Key Concept: Searching vs. Sorting algorithms.\n\n\n3.  **(b) O(1)**\n    * Insertion at the beginning requires adjusting the head pointer, which takes constant time, regardless of the list's size.\n    * Key Concept: Time complexity of linked list operations.\n\n\n4.  **(b) The height difference between the left and right subtrees is at most 1.**\n    * This is the definition of a balanced binary search tree (specifically, an AVL tree condition).  This ensures logarithmic search, insertion, and deletion times.\n    * Key Concept: Balanced Binary Search Tree.\n\n\n5.  **(c) Merge Sort**\n    * Merge Sort uses a divide-and-conquer strategy, recursively dividing the problem into smaller subproblems and then merging the sorted subproblems.  This leads to O(n log n) average-case time complexity.\n    * Key Concept: Merge Sort and its time complexity.\n\n\n\n**Section B: Short Answer Questions**\n\n1. **Difference between Stack and Queue:**\n\n* **Stack:**\n    * LIFO (Last-In, First-Out)\n    * Operations: Push (add element), Pop (remove element), Peek (view top element)\n    * Real-world example: Function call stack, undo/redo mechanisms\n* **Queue:**\n    * FIFO (First-In, First-Out)\n    * Operations: Enqueue (add element), Dequeue (remove element), Front (view front element)\n    * Real-world example: Waiting lines, print queues\n\n\n2. **Binary Search in a Sorted Array:**\n\n* **Steps:**\n    1. Set low = 0, high = n-1 (where n is the array size).\n    2. Calculate mid = (low + high) / 2.\n    3. If array[mid] == target element, return mid (index).\n    4. If array[mid] < target element, set low = mid + 1.\n    5. If array[mid] > target element, set high = mid - 1.\n    6. Repeat steps 2-5 until low > high (element not found).\n\n* Key Concept: Divide and Conquer.\n\n\n3. **Circular Linked List Advantages:**\n\n* **Advantage:**  Easy to traverse from the last element to the first without needing to traverse the whole list again.\n* **Scenario:** Implementing round-robin scheduling, managing resources in a circular fashion (e.g., a buffer).\n* Key Concept:  Circular Linked List vs. Linear Linked List.\n\n\n4. **Time Complexity Calculation:**\n\n* The outer loop runs 'n' times.\n* The inner loop runs 'n-i' times for each value of 'i'.\n* Total number of iterations: n + (n-1) + (n-2) + ... + 1  = n(n+1)/2\n* Time complexity: O(n^2)\n\n\n5. **Recursion:**\n\n* **Concept:**  A function calling itself within its definition.  Requires a base case to stop the recursion.\n* **Example (Factorial):**\n\n```python\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)\n```\n\n\n**Section C: Long Answer Questions**\n\n1. **Patient Record Management System:**\n\n* **Data Structure Choices:**\n    * **Hash Table (HashMap/Dictionary):** Store patient records using patient ID as the key.  O(1) average-case search, insertion, and deletion. Good for quick access.\n    * **Binary Search Tree (BST) or Self-balancing BST (AVL Tree, Red-Black Tree):**  Store patient records based on a specific attribute (e.g., last name). O(log n) search, insertion, and deletion in a balanced tree. Allows for sorted retrieval.\n* **Justification:**\n    * Hash table provides faster access to individual records by ID.\n    * BST allows efficient retrieval of records in a sorted order based on a chosen attribute.  Self-balancing trees prevent worst-case O(n) scenarios.\n\n\n2. **Reversing a Singly Linked List (Iterative):**\n\n```python\ndef reverse_linked_list(head):\n    prev = None\n    curr = head\n    while curr:\n        next_node = curr.next  # Store the next node\n        curr.next = prev       # Reverse the pointer\n        prev = curr           # Move 'prev' one step forward\n        curr = next_node      # Move 'curr' one step forward\n    return prev                # 'prev' is now the new head\n\n```\n\n* **Steps:**\n    1. Initialize `prev` to None, `curr` to the head of the list.\n    2. Iterate while `curr` is not None.\n    3. Store the next node in `next_node`.\n    4. Reverse the `next` pointer of the current node to point to the previous node.\n    5. Move `prev` one step forward (to `curr`).\n    6. Move `curr` one step forward (to `next_node`).\n    7. Return `prev`, which is the new head of the reversed list.\n\n\n3. **Merge Sort vs. Quick Sort for Sorting Customer Orders:**\n\n* **Merge Sort:**\n    * Time Complexity:  O(n log n) in all cases (best, average, worst).\n    * Stable sort (maintains relative order of equal elements).\n    * Requires additional space for merging.\n* **Quick Sort:**\n    * Time Complexity: Average and Best-case: O(n log n), Worst-case: O(n^2) (can be mitigated by randomized pivot selection).\n    * In-place sorting (generally less memory overhead).\n    * Not stable.\n\n* **Choice:** For large datasets, Merge Sort is generally preferred for sorting based on order dates because it guarantees O(n log n) performance even in the worst case, ensuring predictability. While Quick Sort can be faster on average, its worst-case scenario could be detrimental for a large dataset.  The stability of Merge Sort might also be important if orders with the same date need to maintain their original relative order.",
        "metadata": {
            "subject": "Data Structures and Algorithms",
            "topic": "",
            "difficulty": "Medium",
            "total_marks": 35,
            "num_mcq": 5,
            "num_3_marks": 5,
            "num_5_marks": 3
        }
    },
    {
        "id": 4,
        "timestamp": "2025-03-12 02:29:38",
        "questions": "Question Paper\n==================================================\n\n## OPERATING SYSTEMS EXAMINATION\n\n**Time: 3 Hours                                                  Maximum Marks: 80**\n\n**Instructions:**\n\n1. All questions are compulsory.\n2. Write answers clearly and neatly.\n3. Start each section on a new page.\n4. Numbers to the right indicate full marks.\n\n**Subject: Operating Systems**\n**Topic: Memory Management & Scheduling**\n**Difficulty Level: Hard**\n\n\n**Section A: Multiple Choice Questions (20 \u00d7 1 = 20 marks)**\n\n1.  Which of the following memory allocation schemes suffers from external fragmentation?\n    a) Segmentation    b) Paging    c) Demand Paging    d) Swapping [1 Mark]\n\n2.  The optimal page replacement algorithm is:\n    a) FIFO    b) LRU    c) Optimal    d) Clock [1 Mark]\n\n3.  Thrashing occurs when:\n    a) A process spends more time paging than executing.    b) A page fault occurs.    c) The CPU utilization is low.    d) The degree of multiprogramming is low. [1 Mark]\n\n4.  Belady's Anomaly is observed in which page replacement algorithm?\n    a) FIFO    b) LRU    c) Optimal    d) Clock [1 Mark]\n\n5.  Which of the following is NOT a contiguous memory allocation technique?\n    a) First-fit    b) Best-fit    c) Worst-fit    d) Paging [1 Mark]\n\n6.  In a segmented memory system, logical addresses consist of:\n    a) Page number and offset    b) Segment number and offset    c) Page number and frame number    d) Segment number and frame number [1 Mark]\n\n7.  The purpose of a Translation Lookaside Buffer (TLB) is to:\n    a) Speed up memory access    b) Manage page tables    c) Allocate memory frames    d) Handle page faults [1 Mark]\n\n8.  Which scheduling algorithm minimizes average waiting time?\n    a) Shortest Job First (SJF)    b) First Come First Serve (FCFS)    c) Priority Scheduling    d) Round Robin [1 Mark]\n\n9.  A process in the ready state is waiting for:\n    a) I/O    b) Memory    c) CPU    d) Event [1 Mark]\n\n10. Which of the following is a preemptive scheduling algorithm?\n    a) FCFS    b) SJF (Non-preemptive)    c) Round Robin    d) Priority (Non-preemptive) [1 Mark]\n\n11. Context switching saves the state of the:\n    a) Old process     b) New process    c) Both old and new processes    d) None of the above [1 Mark]\n\n12. A deadlock can occur if the following conditions hold simultaneously EXCEPT:\n    a) Mutual exclusion    b) Hold and wait    c) No preemption    d) Starvation [1 Mark]\n\n13. Banker's algorithm is used for:\n    a) Deadlock avoidance    b) Deadlock detection    c) Deadlock prevention    d) Deadlock recovery [1 Mark]\n\n14.  In demand paging, a page is brought into main memory only when:\n     a) It is accessed    b) It is modified    c) It is swapped out    d) It is allocated [1 Mark]\n\n15. The working set model is used for:\n     a) Page replacement    b) Memory allocation    c) Process scheduling    d) Thrashing prevention [1 Mark]\n\n16. A page table entry contains:\n     a) Frame number    b) Presence/Absence bit    c) Protection bits    d) All of the above [1 Mark]\n\n17.  Which scheduling algorithm is suitable for interactive systems?\n     a) FCFS    b) SJF    c) Round Robin    d) Priority [1 Mark]\n\n18. A semaphore is used for:\n     a) Process synchronization    b) Memory management    c) File management    d) I/O management [1 Mark]\n\n19.  A critical section is a code segment that:\n     a) Can be accessed by only one process at a time    b) Can be accessed by multiple processes simultaneously    c) Is always executed by the kernel    d) Is always executed by the user [1 Mark]\n\n20. The degree of multiprogramming refers to:\n     a) The number of processes in memory    b) The number of processors in the system    c) The speed of the CPU    d) The size of the memory [1 Mark]\n\n\n**Section B: Short Answer Questions (15 \u00d7 3 = 45 marks)**\n\n1.  Explain the difference between logical and physical addresses. [3 Marks]\n2.  Describe the working of the FIFO page replacement algorithm with an example. [3 Marks]\n3.  What is segmentation? Explain its advantages and disadvantages. [3 Marks]\n4.  Explain the concept of demand paging. [3 Marks]\n5.  Describe the different types of memory fragmentation. [3 Marks]\n6.  What are the necessary conditions for a deadlock to occur? [3 Marks]\n7.  Explain the difference between preemptive and non-preemptive scheduling. [3 Marks]\n8.  What is the purpose of a process control block (PCB)? [3 Marks]\n9.  Describe the working of the Round Robin scheduling algorithm. [3 Marks]\n10. Explain the concept of a critical section. [3 Marks]\n11. What are semaphores? How are they used for process synchronization? [3 Marks]\n12.  Given a reference string 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1 and 3 frames, calculate the number of page faults using the LRU algorithm. [3 Marks]\n13.  Compare and contrast paging and segmentation. [3 Marks]\n14.  Explain the concept of virtual memory. [3 Marks]\n15.  What is the difference between starvation and deadlock? [3 Marks]\n\n\n\n**Section C: Long Answer Questions (3 \u00d7 5 = 15 marks)**\n\n1.  Consider a system with 4 frames. Calculate the number of page faults using FIFO, LRU, and Optimal page replacement algorithms for the following reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5.  Discuss the performance of each algorithm. [5 Marks]\n\n2.  Discuss the various strategies for dealing with deadlocks. Explain the advantages and disadvantages of each strategy. [5 Marks]\n\n3.  A multiprogramming system has four processes P1, P2, P3, and P4 with arrival times 0, 1, 2, and 3 respectively, and burst times 8, 4, 9, and 5 respectively.  Calculate the average waiting time and turnaround time for each process using the following scheduling algorithms: a) FCFS b) SJF (Preemptive).  Which algorithm performs better in this scenario and why? [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\n**Section A: Multiple Choice Questions**\n\n1.  **a) Segmentation**  Segmentation divides memory into logical segments of varying sizes, leading to external fragmentation as gaps between segments cannot be easily utilized. *Key Concept: External Fragmentation*\n\n2.  **c) Optimal** The optimal algorithm replaces the page that will not be used for the longest period, minimizing page faults. *Key Concept: Page Replacement Algorithms*\n\n3.  **a) A process spends more time paging than executing.** Thrashing occurs when the system spends more time swapping pages than executing instructions. *Key Concept: Thrashing*\n\n4.  **a) FIFO** Belady's Anomaly demonstrates that increasing the number of frames can sometimes increase page faults in the FIFO algorithm. *Key Concept: Belady's Anomaly*\n\n5.  **d) Paging** Paging divides memory into fixed-size pages and is not a contiguous allocation method. *Key Concept: Memory Allocation Techniques*\n\n6.  **b) Segment number and offset** Logical addresses in segmentation consist of a segment number and an offset within that segment. *Key Concept: Segmented Memory*\n\n7.  **a) Speed up memory access** TLB caches recent address translations to reduce the overhead of accessing page tables. *Key Concept: TLB*\n\n8.  **a) Shortest Job First (SJF)** SJF minimizes average waiting time by prioritizing shorter jobs. *Key Concept: Scheduling Algorithms*\n\n9.  **c) CPU** A ready process has all necessary resources except the CPU. *Key Concept: Process States*\n\n10. **c) Round Robin** Round Robin is a preemptive algorithm that allocates a fixed time slice to each process. *Key Concept: Preemptive Scheduling*\n\n11. **a) Old process** Context switching saves the state of the old process so it can be resumed later. *Key Concept: Context Switching*\n\n12. **d) Starvation** Starvation is a related but distinct problem where a process is indefinitely denied resources. Deadlock requires the four Coffman conditions. *Key Concept: Deadlock*\n\n13. **a) Deadlock avoidance** Banker's algorithm ensures the system remains in a safe state, avoiding deadlock. *Key Concept: Deadlock Avoidance*\n\n14. **a) It is accessed** In demand paging, pages are loaded only when needed, upon access. *Key Concept: Demand Paging*\n\n15. **d) Thrashing prevention** The working set model identifies the pages a process actively uses to prevent thrashing. *Key Concept: Working Set Model*\n\n16. **d) All of the above** A page table entry typically contains the frame number, a presence/absence bit, and protection bits. *Key Concept: Page Table*\n\n17. **c) Round Robin** Round robin provides fair CPU allocation and responsiveness, making it suitable for interactive systems. *Key Concept: Interactive Systems*\n\n18. **a) Process synchronization** Semaphores control access to shared resources to prevent race conditions. *Key Concept: Semaphores*\n\n19. **a) Can be accessed by only one process at a time** Critical sections require exclusive access to ensure data consistency. *Key Concept: Critical Section*\n\n20. **a) The number of processes in memory** Degree of multiprogramming indicates the number of processes residing in main memory. *Key Concept: Multiprogramming*\n\n\n**Section B: Short Answer Questions**\n\n1. **Logical vs. Physical Addresses:**\n    * **Logical Address:** Generated by the CPU; refers to a location relative to the program's address space.\n    * **Physical Address:** Actual address in main memory.\n    * **Mapping:** The Memory Management Unit (MMU) translates logical addresses to physical addresses.\n\n2. **FIFO Page Replacement:**\n    * Replaces the oldest page in memory.\n    * **Example:**  Reference string: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5; 3 frames.\n    * Page Faults: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 (12 faults)\n\n3. **Segmentation:**\n    * Divides memory into logical segments based on program structure (code, data, stack).\n    * **Advantages:**  Supports modular programming, efficient use of address space.\n    * **Disadvantages:**  External fragmentation.\n\n4. **Demand Paging:**\n    * Pages are loaded into main memory only when accessed.\n    * Uses a backing store (disk) to hold pages not in memory.\n    * Relies on page tables and the concept of \"present/absent\" bits.\n\n5. **Memory Fragmentation:**\n    * **Internal Fragmentation:** Wasted space within a allocated memory block (e.g., fixed-size partitions).\n    * **External Fragmentation:**  Wasted space between allocated blocks (e.g., segmentation).\n\n6. **Necessary Conditions for Deadlock:**\n    * Mutual Exclusion\n    * Hold and Wait\n    * No Preemption\n    * Circular Wait\n\n7. **Preemptive vs. Non-preemptive Scheduling:**\n    * **Preemptive:**  OS can interrupt a running process to schedule another. (e.g., Round Robin)\n    * **Non-preemptive:**  A process runs to completion or blocks before another can be scheduled. (e.g., FCFS)\n\n8. **Process Control Block (PCB):**\n    * Data structure containing information about a process.\n    * Includes: process ID, state, program counter, registers, memory limits, open files, etc.\n\n9. **Round Robin Scheduling:**\n    * Each process gets a time slice (quantum).\n    * After the time slice expires, the process is preempted and moved to the ready queue.\n\n10. **Critical Section:**\n    * Code segment that accesses shared resources.\n    * Only one process can be in a critical section at a time.\n    * Requires synchronization mechanisms (e.g., semaphores, mutexes).\n\n11. **Semaphores:**\n    * Integer variables used for process synchronization.\n    * Two operations: wait() and signal().\n    * Used to control access to shared resources and coordinate process execution.\n\n12. **LRU Page Replacement Calculation:**\n    * Reference string: 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1\n    * 3 frames\n    * Page Faults: 18\n\n13. **Paging vs. Segmentation:**\n    * Paging: Fixed-size blocks, physical division.\n    * Segmentation: Variable-size blocks, logical division.\n    * Both support virtual memory.\n\n14. **Virtual Memory:**\n    * Allows processes to address a larger memory space than physically available.\n    * Uses secondary storage (disk) as an extension of RAM.\n    * Implemented using demand paging or segmentation.\n\n15. **Starvation vs. Deadlock:**\n    * Starvation: A process indefinitely waits for resources.\n    * Deadlock: A set of processes are blocked, waiting for each other to release resources.\n\n\n**Section C: Long Answer Questions**\n\n1. **Page Replacement Algorithms Comparison:**\n\n    | Reference String | 1 | 2 | 3 | 4 | 1 | 2 | 5 | 1 | 2 | 3 | 4 | 5 |\n    |---|---|---|---|---|---|---|---|---|---|---|---|---|\n    | FIFO (4 Frames) | F | F | F | F | H | H | F | H | H | F | F | F |  (9 Page Faults)\n    | LRU (4 Frames) | F | F | F | F | H | H | F | H | H | F | F | F |  (9 Page Faults)\n    | Optimal (4 Frames) | F | F | F | F | H | H | F | H | H | H | H | F | (8 Page Faults)\n    * **F:** Page Fault,  **H:** Hit\n\n    Optimal performs best as it minimizes page faults. FIFO and LRU exhibit similar performance in this specific case.\n\n\n2. **Deadlock Handling Strategies:**\n    * **Prevention:** Design the system to eliminate one or more of the four Coffman conditions. (e.g., resource ordering)\n    * **Avoidance:** Use algorithms like the Banker's algorithm to avoid unsafe states.\n    * **Detection:** Periodically check for deadlocks using resource allocation graphs.\n    * **Recovery:**  Terminate processes or preempt resources to break the deadlock.\n\n\n3. **Scheduling Algorithm Comparison:**\n\n    * **FCFS:**\n        * P1: WT=0, TAT=8\n        * P2: WT=8, TAT=12\n        * P3: WT=12, TAT=21\n        * P4: WT=21, TAT=26\n        * Avg WT = 10.25, Avg TAT = 16.75\n\n    * **SJF (Preemptive):**\n        * P1: WT=17, TAT=25\n        * P2: WT=3, TAT=7\n        * P3: WT=8, TAT=17\n        * P4: WT=0, TAT=5\n        * Avg WT = 7, Avg TAT = 13.5\n\n\n    SJF (Preemptive) performs better in this scenario as it minimizes the average waiting and turnaround times by prioritizing shorter jobs.  FCFS suffers from the convoy effect where shorter jobs are delayed by longer ones.",
        "metadata": {
            "subject": "Operating Systems",
            "topic": "Memory Management",
            "difficulty": "Hard",
            "total_marks": 80,
            "num_mcq": 20,
            "num_3_marks": 15,
            "num_5_marks": 3
        }
    },
    {
        "id": 5,
        "timestamp": "2025-03-12 02:32:11",
        "questions": "Question Paper\n==================================================\n\n## CUSTOM EXAMINATION\n\n**Time:** 3 Hours                                                  **Maximum Marks:** 96\n\n**Instructions:**\n1. All questions are compulsory.\n2. Write answers clearly and neatly.\n3. Start each section on a new page.\n4. Numbers to the right indicate full marks.\n\n**Subject:** Computer Organization and Architecture\n**Topic:** Comprehensive Examination\n**Syllabus Coverage:** Units I-VI (as specified in the prompt)\n**Difficulty Level:** Hard\n\n\n**Section A: Multiple Choice Questions (10 \u00d7 1 = 10 marks)**\n\n1.  Which of the following is NOT a characteristic of RISC architecture?\n    a) Large number of instructions      b) Simple addressing modes\n    c) Fixed-length instructions        d) Complex instruction set [1 Mark]\n\n2.  In a three-state bus buffer, the high-impedance state is used for:\n    a) Data transfer                 b) Bus arbitration\n    c) Clock synchronization          d) Interrupt handling [1 Mark]\n\n3.  The Booth algorithm is used for:\n    a) Multiplication of floating-point numbers   b) Division of integers\n    c) Multiplication of signed integers          d) Division of floating-point numbers [1 Mark]\n\n4.  Which memory hierarchy level is typically the fastest?\n    a) Main memory                    b) Cache memory\n    c) Secondary memory                d) Register file [1 Mark]\n\n5.  DMA stands for:\n    a) Direct Memory Access            b) Digital Memory Allocation\n    c) Dynamic Memory Access           d) Differentiated Memory Architecture [1 Mark]\n\n6.  Which interrupt has the highest priority?\n    a) Trap                           b) External Interrupt\n    c) Software Interrupt             d) Non-maskable Interrupt [1 Mark]\n\n7.  A microprogram is stored in:\n    a) RAM                            b) ROM\n    c) Control Memory                 d) Cache [1 Mark]\n\n8.  Flynn's taxonomy classifies parallel processors based on:\n    a) Instruction and data streams     b) Memory hierarchy levels\n    c) Clock speed                    d) Number of registers [1 Mark]\n\n9.  The exponent in floating-point representation typically uses:\n    a) Sign-magnitude representation     b) Two's complement representation\n    c) Biased representation            d) One's complement representation [1 Mark]\n\n10. Which addressing mode uses a register to store the memory address?\n    a) Direct                         b) Indirect\n    c) Register indirect              d) Immediate [1 Mark]\n\n\n**Section B: Short Answer Questions (12 \u00d7 3 = 36 marks)**\n\n1.  Explain the difference between fixed-point and floating-point representation. Give examples. [3 Marks]\n2.  Describe the steps involved in a typical instruction cycle. [3 Marks]\n3.  What are the advantages of using subroutines in assembly language programming? [3 Marks]\n4.  Explain the concept of address sequencing in microprogrammed control. [3 Marks]\n5.  Compare and contrast CISC and RISC architectures. [3 Marks]\n6.  Explain the concept of pipelining and its advantages. [3 Marks]\n7.  Describe different types of interconnection structures used in multiprocessors. [3 Marks]\n8.  Explain the concept of cache coherence in multiprocessor systems. [3 Marks]\n9.  Describe the working of a three-state bus buffer with a suitable diagram. [3 Marks]\n10. Explain two different multiplication algorithms. [3 Marks]\n11. Discuss different asynchronous data transfer methods. [3 Marks]\n12. Briefly explain the concept of virtual memory. [3 Marks]\n\n\n**Section C: Long Answer Questions (10 \u00d7 5 = 50 marks)**\n\n1.  Design an accumulator unit for a basic computer. Explain its functionality with a diagram. [5 Marks]\n2.  Write an assembly language program (using a hypothetical instruction set) to find the factorial of a number. [5 Marks]\n3.  Explain the design of a microprogrammed control unit with a suitable example. [5 Marks]\n4.  Discuss different addressing modes with examples. How do addressing modes affect instruction execution? [5 Marks]\n5.  Explain Flynn's taxonomy in detail.  Discuss the advantages and disadvantages of each category. [5 Marks]\n6.  Explain the concept of vector processing and its application in array processors. [5 Marks]\n7.  Compare and contrast different division algorithms.  Analyze their performance in terms of speed and complexity. [5 Marks]\n8.  Discuss different types of interrupts and their handling mechanisms.  Explain the role of priority interrupts. [5 Marks]\n9.  Design a memory hierarchy system for a modern computer.  Justify your choices for different memory levels. [5 Marks]\n10. Case Study: A multiprocessor system experiences frequent cache coherence issues. Analyze the possible causes and propose solutions to improve system performance. [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\n**Section A: Multiple Choice Questions**\n\n1.  **d) Complex instruction set**\n    * RISC architectures are characterized by a *reduced* instruction set, simple addressing modes, and fixed-length instructions.\n    * Key concept: RISC vs. CISC architectures\n\n2.  **b) Bus arbitration**\n    * The high-impedance state allows multiple devices to share the bus without conflicts. It effectively disconnects the buffer from the bus.\n    * Key concept: Bus arbitration and tri-state buffers\n\n3.  **c) Multiplication of signed integers**\n    * Booth's algorithm simplifies multiplication of signed integers by handling positive and negative numbers efficiently.\n    * Key concept: Integer multiplication algorithms\n\n4.  **d) Register file**\n    * Registers are the fastest memory elements within the CPU, providing quick access to frequently used data.\n    * Key concept: Memory hierarchy and access times\n\n5.  **a) Direct Memory Access**\n    * DMA allows peripherals to transfer data directly to/from main memory without CPU intervention.\n    * Key concept: DMA and I/O operations\n\n6.  **d) Non-maskable Interrupt**\n    * NMI has the highest priority and cannot be disabled by software. It's typically used for critical errors.\n    * Key concept: Interrupt priorities and handling\n\n7.  **c) Control Memory**\n    * Microprograms, which define the control signals for each instruction, are stored in a special memory called control memory.\n    * Key concept: Microprogrammed control\n\n8.  **a) Instruction and data streams**\n    * Flynn's taxonomy classifies architectures based on the number of instruction and data streams processed concurrently.\n    * Key concept: Parallel processing architectures\n\n9.  **c) Biased representation**\n    * A bias is added to the exponent to represent both positive and negative exponents without using a separate sign bit.\n    * Key concept: Floating-point representation\n\n10. **c) Register indirect**\n    * The register holds the memory address, and the operand is fetched from that address.\n    * Key concept: Addressing modes\n\n\n**Section B: Short Answer Questions**\n\n1.  **Fixed-Point vs. Floating-Point:**\n    * **Fixed-Point:** Represents numbers with a fixed decimal point.  Example: 12.34 (implied decimal). Simpler hardware. Limited range and precision.\n    * **Floating-Point:** Represents numbers in scientific notation (mantissa x base^exponent). Example: 1.234 x 10^1. Wider range and precision. More complex hardware.  IEEE 754 standard.\n\n2.  **Instruction Cycle:**\n    * **Fetch:** Retrieve instruction from memory.\n    * **Decode:** Interpret the instruction opcode and operands.\n    * **Execute:** Perform the operation specified by the instruction.\n    * **Memory Access (if needed):** Read/write data from/to memory.\n    * **Write Back (if needed):** Store the result in a register.\n\n3.  **Advantages of Subroutines:**\n    * **Modularity:** Break down complex programs into smaller, manageable units.\n    * **Reusability:**  Same subroutine can be called multiple times.\n    * **Code Size Reduction:** Avoids code duplication.\n    * **Improved Readability:** Easier to understand and maintain.\n\n4.  **Address Sequencing in Microprogrammed Control:**\n    * Determines the next microinstruction to be executed.\n    * Techniques: Sequential addressing, branching (conditional and unconditional), mapping.\n    * Allows for flexible and complex control sequences.\n\n5.  **CISC vs. RISC:**\n    * **CISC:** Complex instruction set, variable-length instructions, multiple addressing modes, microprogrammed control. Emphasis on powerful instructions.\n    * **RISC:** Reduced instruction set, fixed-length instructions, simple addressing modes, hardwired control. Emphasis on simpler, faster instructions.\n\n6.  **Pipelining:**\n    * Overlapping the execution of multiple instructions.\n    * Stages: Fetch, Decode, Execute, Memory Access, Write Back.\n    * Advantages: Increased instruction throughput, improved performance.\n\n7.  **Interconnection Structures:**\n    * **Bus:** Shared communication pathway.\n    * **Crossbar Switch:** Dedicated connection between each processor and memory module.\n    * **Multistage Interconnection Network (MIN):** Network of switching elements.\n    * **Mesh/Torus:** Processors connected in a grid.\n\n8.  **Cache Coherence:**\n    * Ensuring data consistency across multiple caches in a multiprocessor system.\n    * Techniques: Write-through, write-back, snooping protocols.\n\n9.  **Three-State Bus Buffer:**\n    * Diagram showing buffer with input, output, and control signal.\n    * States: Enabled (data passes through), Disabled (high-impedance), allowing multiple devices to share the bus.\n\n10. **Multiplication Algorithms:**\n    * **Booth's Algorithm:** Handles signed integers efficiently by reducing the number of additions/subtractions.\n    * **Array Multiplier:** Uses a grid of AND gates and adders for parallel multiplication.  Faster but requires more hardware.\n\n11. **Asynchronous Data Transfer:**\n    * **Strobe Control:**  Sender asserts a strobe signal to indicate data validity. Receiver acknowledges receipt.\n    * **Handshaking:** More complex, involves request and acknowledge signals for reliable data transfer.\n    * **Interrupts:** Device interrupts the CPU to signal data availability.\n\n12. **Virtual Memory:**\n    * Extends the addressable memory space beyond physical RAM.\n    * Uses secondary storage (disk) as an extension of main memory.\n    * Paging/segmentation techniques.\n    * Manages memory allocation and swapping between RAM and disk.\n\n\n**Section C: Long Answer Questions**\n\n1.  **Accumulator Unit Design:**\n    * Diagram showing accumulator register, ALU, and connections to data bus and control unit.\n    * Functionality: Performs arithmetic and logical operations.  Accumulator stores one operand and the result.  Explain data flow and control signals.\n\n2.  **Assembly Language Program for Factorial:**\n    * Hypothetical instruction set (LOAD, STORE, MUL, DEC, JZ, etc.).\n    * Program logic: Initialize accumulator to 1, loop from N down to 1, multiplying accumulator by the loop counter in each iteration.\n\n3.  **Microprogrammed Control Unit Design:**\n    * Diagram showing control memory, address register, microinstruction register, and control signal generator.\n    * Example: Microcode for a simple instruction (e.g., ADD).\n    * Explain how microinstructions control the datapath.\n\n4.  **Addressing Modes:**\n    * **Direct:** Operand is the memory address.\n    * **Indirect:**  Operand is the address of the memory location containing the actual address.\n    * **Register Indirect:** Operand is fetched from the memory location pointed to by a register.\n    * **Immediate:** Operand is part of the instruction.\n    * **Indexed:** Address calculated by adding a register value to an offset.\n    * Effect on Instruction Execution: Addressing modes influence how operands are fetched and how instructions are executed.\n\n5.  **Flynn's Taxonomy:**\n    * **SISD:** Single instruction, single data.\n    * **SIMD:** Single instruction, multiple data (e.g., vector processors).\n    * **MIMD:** Multiple instructions, multiple data (e.g., multiprocessors).\n    * **MISD:** Multiple instructions, single data (less common).\n    * Advantages and disadvantages of each category based on complexity, cost, performance, and applications.\n\n6.  **Vector Processing:**\n    * Processing entire arrays of data with single instructions.\n    * Applications in array processors, scientific computing, graphics processing.\n    * Advantages: Increased throughput, efficient handling of large datasets.\n\n7.  **Division Algorithms:**\n    * **Restoring Division:** Simpler but slower.\n    * **Non-Restoring Division:** Faster but more complex.\n    * **SRT Division:** Uses lookup tables for faster quotient digit selection.\n    * Comparison based on speed, complexity, and hardware requirements.\n\n8.  **Interrupts:**\n    * **External Interrupts:** Generated by external devices (e.g., I/O devices).\n    * **Internal Interrupts:** Generated by the CPU (e.g., traps, exceptions).\n    * **Software Interrupts:** Generated by software instructions.\n    * Handling mechanisms: Interrupt vector table, priority interrupts, interrupt service routines.\n\n9.  **Memory Hierarchy Design:**\n    * Levels: Registers, L1 cache, L2 cache, L3 cache, main memory, secondary storage.\n    * Justification for choices based on access speed, cost, and capacity.  Consider factors like cache size, associativity, and replacement policies.\n\n10. **Case Study: Cache Coherence Issues:**\n    * Possible causes:  Write-back caches without proper snooping protocols, inconsistent cache updates, race conditions.\n    * Solutions: Implement a robust cache coherence protocol (e.g., MESI), optimize data sharing patterns, use hardware-assisted coherence mechanisms.",
        "metadata": {
            "subject": "Custom",
            "topic": "",
            "difficulty": "Hard",
            "total_marks": 100,
            "num_mcq": 10,
            "num_3_marks": 12,
            "num_5_marks": 10
        }
    },
    {
        "id": 6,
        "timestamp": "2025-03-12 02:34:23",
        "questions": "Question Paper\n==================================================\n\nCUSTOM EXAMINATION\nTime: 3 Hours                                                  Maximum Marks: 48\n\nInstructions:\n1. All questions are compulsory\n2. Write answers clearly and neatly\n3. Start each section on a new page\n4. Numbers to the right indicate full marks\n\nSubject: Theory of Computation\nTopic: Formal Languages and Automata\nSyllabus Coverage: UNIT III, IV, and V (as specified)\n\nDifficulty Level: Easy\n\n\n**Section A: Multiple Choice Questions (5 \u00d7 1 = 5 marks)**\n\n1. Which of the following is NOT a component of a Context-Free Grammar (CFG)?\n    (a) Terminals\n    (b) Non-terminals\n    (c) Start symbol\n    (d) States\n\n2. A pushdown automaton uses which data structure?\n    (a) Queue\n    (b) Stack\n    (c) Linked List\n    (d) Tree\n\n3. Chomsky Normal Form restricts the right-hand side of productions to:\n    (a) A single terminal or two non-terminals\n    (b) Any number of terminals and non-terminals\n    (c) A single non-terminal\n    (d) Two terminals\n\n4. The Pumping Lemma for CFLs is used to:\n    (a) Prove a language is regular\n    (b) Prove a language is context-free\n    (c) Prove a language is not context-free\n    (d) Simplify CFGs\n\n5. Which of the following is an undecidable problem?\n    (a) Checking if a given string is accepted by a DFA\n    (b) Checking if a given CFG is ambiguous\n    (c) Checking if the language of a given Turing Machine is empty\n    (d) Checking if a given regular expression is valid\n\n\n**Section B: Short Answer Questions (6 \u00d7 3 = 18 marks)**\n\n1.  Construct a CFG for the language L = {a<sup>n</sup>b<sup>n</sup> | n \u2265 0}. [3 Marks]\n\n2.  Explain the concept of ambiguity in grammars with an example. [3 Marks]\n\n3.  Describe the difference between a deterministic and a non-deterministic pushdown automaton. [3 Marks]\n\n4. Convert the following CFG to Chomsky Normal Form: S \u2192 aSb | \u03b5. [3 Marks]\n\n5. State the Pumping Lemma for Context-Free Languages. [3 Marks]\n\n6. What is the significance of closure properties of CFLs? Give an example of one such property. [3 Marks]\n\n\n**Section C: Long Answer Questions (5 \u00d7 5 = 25 marks)**\n\n1.  Design a pushdown automaton that accepts the language L = {wcw<sup>R</sup> | w \u2208 {a, b}*}, where w<sup>R</sup> is the reverse of w. Show the transition table and explain the acceptance process. [5 Marks]\n\n2.  Prove that the language L = {a<sup>n</sup>b<sup>n</sup>c<sup>n</sup> | n \u2265 1} is not context-free using the Pumping Lemma. [5 Marks]\n\n3.  Explain the concept of a Turing Machine. Describe its components and how it operates. [5 Marks]\n\n4.  Discuss the Halting Problem. Explain why it is undecidable. [5 Marks]\n\n5.  Describe the Post's Correspondence Problem. Give an example instance of the problem and its solution.  [5 Marks]",
        "answers": "Answer Key==================================================\n\nANSWER KEY\n==========\n\n**Section A: Multiple Choice Questions**\n\n1. **(d) States**  States are components of Automata, not of Context-Free Grammars. Key concept: CFG components.\n2. **(b) Stack**  A pushdown automaton uses a stack for storing and retrieving symbols during processing. Key concept: PDA operation.\n3. **(a) A single terminal or two non-terminals** This is the defining characteristic of Chomsky Normal Form. Key concept: CFG simplification.\n4. **(c) Prove a language is not context-free**  The Pumping Lemma provides a contradiction method to show a language isn't context-free. Key concept: CFL properties.\n5. **(c) Checking if the language of a given Turing Machine is empty** This is equivalent to the halting problem, which is undecidable.  Key concept: Decidability.\n\n\n\n**Section B: Short Answer Questions**\n\n1. **Construct a CFG for L = {a<sup>n</sup>b<sup>n</sup> | n \u2265 0}.**\n    *   S \u2192 aSb  (for generating equal numbers of a's and b's)\n    *   S \u2192 \u03b5   (for the case n = 0)\n    *   Key concept: CFG construction for simple languages\n\n2. **Explain ambiguity in grammars with an example.**\n    *   A grammar is ambiguous if a string can have multiple derivation trees.\n    *   Example: S \u2192 SS | (S) | \u03b5;  String: ()() can be derived in multiple ways.\n    *   Key concept: Parse tree, Ambiguity\n\n3. **Difference between deterministic and non-deterministic PDA.**\n    *   DPA: For each input symbol and stack top, there is at most one possible transition.\n    *   NPDA: For each input symbol and stack top, there can be multiple possible transitions.\n    *   NPDAs are more powerful than DPAs in terms of the languages they can accept.\n    *   Key concept: PDA variations\n\n4. **Convert CFG to Chomsky Normal Form: S \u2192 aSb | \u03b5.**\n    * Introduce new start symbol:  S<sub>0</sub> \u2192 S\n    * Handle the \u03b5 production:  S<sub>0</sub> \u2192 S | \u03b5 ; S \u2192 aSb\n    * Replace terminals: S \u2192 XSY ; X \u2192 a ; Y \u2192 b\n    * Break down long productions: S \u2192 XA ; A \u2192 SY\n    * Result:  S<sub>0</sub> \u2192 S | \u03b5 ; S \u2192 XA | \u03b5 ; X \u2192 a ; Y \u2192 b ; A \u2192 SY \n    * Key concept: CNF conversion steps\n\n5. **State the Pumping Lemma for CFLs.**\n    * For any CFL L, there exists a pumping length p such that any string w in L with |w| \u2265 p can be divided into five parts uvxyz, satisfying:\n        1. |vxy| \u2264 p\n        2. |vy| > 0\n        3. For all i \u2265 0, uv<sup>i</sup>xy<sup>i</sup>z \u2208 L\n    * Key concept: Pumping Lemma conditions\n\n6. **Significance of closure properties of CFLs. Give an example.**\n    * Closure properties help determine if operations on CFLs result in another CFL.\n    * Example: CFLs are closed under union. If L1 and L2 are CFLs, then L1 \u222a L2 is also a CFL.\n    * Key concept: Closure properties, Language operations\n\n\n**Section C: Long Answer Questions**\n\n1. **Design a PDA for L = {wcw<sup>R</sup> | w \u2208 {a, b}*}.**\n    * Push the symbols of w onto the stack.\n    * When 'c' is encountered, switch to the second phase.\n    * Match the remaining input symbols with the stack top; pop if they match.\n    * Accept if the stack is empty at the end of the input.\n    * Transition table (example, using state notation):\n        * \u03b4(q0, a, \u03b5) = (q0, a) // Push 'a'\n        * \u03b4(q0, b, \u03b5) = (q0, b) // Push 'b'\n        * \u03b4(q0, c, \u03b5) = (q1, \u03b5) // Transition to matching phase\n        * \u03b4(q1, a, a) = (q1, \u03b5) // Pop 'a'\n        * \u03b4(q1, b, b) = (q1, \u03b5) // Pop 'b'\n        * \u03b4(q1, \u03b5, \u03b5) = (q2, \u03b5) // Accept if stack is empty\n\n2. **Prove L = {a<sup>n</sup>b<sup>n</sup>c<sup>n</sup> | n \u2265 1} is not context-free.**\n    * Assume L is context-free. Let p be the pumping length.\n    * Choose w = a<sup>p</sup>b<sup>p</sup>c<sup>p</sup>.\n    * Divide w into uvxyz according to the Pumping Lemma.\n    * Consider cases for the location of vxy:\n        * Case 1: vxy contains only one type of symbol (a, b, or c). Pumping up or down will violate the equal number constraint.\n        * Case 2: vxy contains two types of symbols. Pumping will again create an imbalance.\n    * In all cases, pumping violates the language definition, contradicting the Pumping Lemma. Therefore, L is not context-free.\n\n\n3. **Explain the concept of a Turing Machine.**\n    * A Turing Machine is a theoretical model of computation.\n    * Components:\n        * Infinite tape divided into cells\n        * Read/write head\n        * Finite control unit (states, transitions)\n    * Operation:\n        * Reads the symbol under the head\n        * Based on the current state and symbol, it writes a new symbol, moves the head left or right, and changes state.\n\n4. **Discuss the Halting Problem. Explain its undecidability.**\n    * Halting Problem: Determining whether an arbitrary Turing Machine will halt (stop) on a given input.\n    * Undecidable: No algorithm can solve the halting problem for all possible inputs.\n    * Proof by contradiction: Assume a halting decider H exists. Construct a new machine D that loops if H says it halts and halts if H says it loops. Feeding D to itself leads to a paradox, proving H cannot exist.\n\n5. **Describe Post's Correspondence Problem.**\n    * Given two lists of strings (list A and list B) of equal length, find a sequence of indices such that the concatenation of strings from list A at those indices equals the concatenation of strings from list B at the same indices.\n    * Example:\n        * List A: [a, ab, bba]\n        * List B: [baa, a, bb]\n        * Solution: [1, 2, 1, 3]  (a ab bba a) = (baa a bb baa)\n    * PCP is undecidable in the general case.",
        "metadata": {
            "subject": "Custom",
            "topic": "",
            "difficulty": "Easy",
            "total_marks": 50,
            "num_mcq": 5,
            "num_3_marks": 6,
            "num_5_marks": 5
        }
    },
    {
        "id": 7,
        "timestamp": "2025-04-05 17:37:51",
        "questions": "Error generating content: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\ndomain: \"googleapis.com\"\nmetadata {\n  key: \"service\"\n  value: \"generativelanguage.googleapis.com\"\n}\n, locale: \"en-US\"\nmessage: \"API key not valid. Please pass a valid API key.\"\n]",
        "answers": null,
        "metadata": null
    }
]